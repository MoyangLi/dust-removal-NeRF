# dust-removal-NeRF
 The code is based on the codebase [NeRF-pytorch](https://github.com/yenchenlin/nerf-pytorch)

[NeRF](http://www.matthewtancik.com/nerf) (Neural Radiance Fields) is a method that achieves state-of-the-art results for synthesizing novel views of complex scenes. When taking photos through the dusty glass, we observed the dust will affect the quality of pictures. So we proposed a NeRF-based model and utilized the principle of volume rendering to reconstruct scenes without contamination.

In the future, this project will be integrated into SLAM systems used for severe environments like hoggery, heavy fog. In the hoggery, drips of water on the camera lens will cause huge performance degradation due the low-quality images. We hope to implement our approach in SLAM systems to help simultaneously reconstruct high-quality scenes and localize accurately.

Here are some videos generated by this repository.

<img src=https://user-images.githubusercontent.com/48423818/203497703-c47c187f-18e4-44b4-a59b-bf6f60b6caca.gif width=45% /> <img src=https://user-images.githubusercontent.com/48423818/203498119-bb6f8597-7752-4910-83b3-f4fced409eec.gif width=45% />

<!-- ![wall_clean](https://user-images.githubusercontent.com/48423818/203498119-bb6f8597-7752-4910-83b3-f4fced409eec.gif) -->

The left is the viedo generated with the original NeRF, and the right is the video after removing the dust on the glass. It is clearly seen that our method achieved good performance on the real-world datasets.

## Installation

```
git clone https://github.com/moyangli-cursed-child/dust-removal-NeRF.git
cd dust-removal-NeRF
pip install -r requirements.txt
```

<details>
  <summary> Dependencies (click to expand) </summary>
  
  ## Dependencies
  - PyTorch 1.4
  - matplotlib
  - numpy
  - imageio
  - imageio-ffmpeg
  - configargparse
  
</details>

## Further Experiment
Furthermore, we aggravated the level of dusty glass and utilized an artificial scene to verify our method. We found that we could not simply wipe off the mud using our method and analysed the density distribution of sampled point along the rendering rays. 
Finally we re-selected the threshold of rendering range and got satisfactory results. The below is the experiment results of the artificial scene.

<img src=https://user-images.githubusercontent.com/48423818/203354010-7513d94c-ed43-4161-a7f4-3ccdb98df0bc.gif width=45% /> <img src=https://user-images.githubusercontent.com/48423818/203354106-46435cff-5b78-4617-bfa3-688692c48ff7.gif width=45% />

## Analysis of Density Distribution
<img src=https://user-images.githubusercontent.com/48423818/203500765-471e27e4-6f2c-4276-844d-4611679ea7fe.png width=70% />
<img src=https://user-images.githubusercontent.com/48423818/203500818-2e5182cc-48af-4a70-8ef2-6cc1470f03a7.png width=70% />
<img src=https://user-images.githubusercontent.com/48423818/203500846-4a6d66cf-26fe-4694-af7d-766e28b9c7f2.png width=70% />

Form the above results of density distribution, we could see that the particle distribution of dust is not as sharp as we expected. As the glass is coated with a film of dust, we expect that corresponding volume density should only peak in a small interval of depth or several depth values. However, we notice that the distribution is more like smooth Gaussian distribution which will lead to artifacts and inaccurate depth image.


## Problems and Possible Solutions
- the dust will cause the obstruction of scene, thus leading to holes in synthetic new views.
- dust could not be removed completely due the character of density distribution.
- the holes could not be filled with surrounding pixels and multi-view information.

- Solution 1: find the optimal boundary?
- Solution 2: holes filled with the help of incorporation of extra multi-view regularization? Combined with our work Geo-NeRF
- Solution 3: force density distribution to be sharper? Compare with InfoNeRF
- Solution 4: utilize two NeRF model the dust and scene separately? Introduce extra regularization to make sure the dust comply to some supposal?
